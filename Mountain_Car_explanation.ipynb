{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5Z6f1PmEJuJVGDsI26Amg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taylan-sen/CIS355_intro_to_ai/blob/main/Mountain_Car_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook is additional code to test each agent out many times."
      ],
      "metadata": {
        "id": "uX1vPrQzEJZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The line below directs the OS to install renderlab python module\n",
        "# As part of installing renderlab, it should also install gymnasium\n",
        "!pip install renderlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4diV-nUZCsT",
        "outputId": "c3946893-3441-4cef-c751-3b0712a3c5fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting renderlab\n",
            "  Downloading renderlab-0.1.20230421184216-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from renderlab) (1.0.3)\n",
            "Collecting gymnasium (from renderlab)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium->renderlab)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.35.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->renderlab) (10.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy->renderlab) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2024.8.30)\n",
            "Downloading renderlab-0.1.20230421184216-py3-none-any.whl (4.0 kB)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, renderlab\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 renderlab-0.1.20230421184216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym          # the new gym simulation environments\n",
        "import renderlab as rl           # to play simulations as videos in colab\n",
        "import numpy as np               # for fast arrays\n",
        "import matplotlib.pyplot as plt  # for plotting\n",
        "print('import successful')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBm9ErwEhWCM",
        "outputId": "6f96bc7e-7dcf-4028-8aa6-582df375bc57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code below, we define a function called eval_agent to run each agent many times to look at the results. Note how different performance measures resut in different agents beaing preferred (i.e. the performance measure might be best average, best performance out of 100 runs, highest percentage of cars making it to flag)."
      ],
      "metadata": {
        "id": "FTMOrrJHYyTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent(step, position, velocity):\n",
        "  \"\"\"This agent will go a fixed number of steps reverse, then go forward.\n",
        "  This is an open loop agent, since there is no feedback loop. In other\n",
        "  words, the agent is not using the sensor position or velocity at all.\"\"\"\n",
        "  num_steps_reverse = 40\n",
        "  if step < num_steps_reverse:\n",
        "    action = 0\n",
        "  else:\n",
        "    action = 2\n",
        "  return action\n",
        "\n",
        "def smart_agent(step, position, velocity):\n",
        "  \"\"\"This agent will pick the forward action when velocity is positive and\n",
        "  will pick the reverse action when the velocity is not positive.\"\"\"\n",
        "  if velocity > 0:\n",
        "    action = 2\n",
        "  else:\n",
        "    action = 0\n",
        "  return action\n",
        "\n",
        "def eval_agent(agent_input, num_iterations = 100):\n",
        "  \"\"\"Runs the agent num_interations number of times and save the number of steps\n",
        "  each run took. Prints all scores as well as the average and low. \"\"\"\n",
        "  # create the simulator environment\n",
        "  env = gym.make(\"MountainCar-v0\", render_mode = \"rgb_array\")\n",
        "  env = rl.RenderFrame(env, \"./output\")\n",
        "\n",
        "  resulting_steps_list = []\n",
        "  for i in range(num_iterations):\n",
        "\n",
        "    # initialize simulator\n",
        "    step = 0\n",
        "    observation, info = env.reset()\n",
        "\n",
        "    while True:\n",
        "      position, velocity = observation\n",
        "      action = agent_input(step, position, velocity)\n",
        "      observation, reward, terminated, truncated, info = env.step(action)\n",
        "      step += 1\n",
        "      if terminated or truncated:\n",
        "        break\n",
        "    resulting_steps_list.append(step) # save the score\n",
        "\n",
        "  print('---------------')\n",
        "  print('simulation complete')\n",
        "  print('# iterations evaluated = ', num_iterations)\n",
        "  print('average score(steps) = ', sum(resulting_steps_list)/num_iterations)\n",
        "  print('best score (lowest steps) = ', min(resulting_steps_list))\n",
        "  x = np.array(resulting_steps_list)\n",
        "  print('percent that reach the flag:', sum(x < 200)/num_iterations)\n",
        "  print('---------------')\n",
        "  print('all scores:')\n",
        "  print(resulting_steps_list)\n"
      ],
      "metadata": {
        "id": "A_zGnN9y_b6t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_agent(agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEFiPLOxSTy5",
        "outputId": "3a16b659-3a96-4717-df1d-6cf19a1c848f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "simulation complete\n",
            "# iterations evaluated =  100\n",
            "average score(steps) =  153.55\n",
            "best score (lowest steps) =  85\n",
            "percent that reach the flag: 0.45\n",
            "---------------\n",
            "all scores:\n",
            "[200, 200, 200, 96, 89, 93, 200, 90, 200, 200, 97, 200, 200, 92, 87, 90, 200, 200, 200, 200, 200, 200, 86, 200, 86, 85, 138, 200, 200, 104, 200, 92, 200, 200, 86, 200, 134, 200, 101, 200, 95, 98, 200, 85, 200, 200, 98, 86, 200, 200, 200, 200, 200, 200, 200, 91, 200, 88, 97, 200, 200, 88, 85, 89, 102, 102, 200, 87, 88, 200, 200, 95, 200, 94, 99, 90, 200, 200, 200, 200, 200, 200, 200, 104, 200, 88, 180, 200, 200, 200, 89, 86, 200, 94, 200, 200, 88, 107, 200, 116]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_agent(smart_agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ztOEdf4SWZx",
        "outputId": "433a9613-39ae-48ad-fd51-bb2b44688c87"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------\n",
            "simulation complete\n",
            "# iterations evaluated =  100\n",
            "average score(steps) =  125.59\n",
            "best score (lowest steps) =  86\n",
            "percent that reach the flag: 1.0\n",
            "---------------\n",
            "all scores:\n",
            "[158, 96, 95, 159, 87, 93, 86, 86, 99, 163, 97, 89, 103, 105, 156, 151, 164, 152, 87, 161, 153, 96, 99, 88, 155, 89, 156, 88, 178, 153, 159, 104, 154, 86, 86, 87, 151, 102, 90, 153, 87, 166, 98, 152, 156, 153, 155, 159, 153, 87, 89, 153, 90, 156, 153, 92, 87, 158, 173, 151, 102, 93, 155, 170, 86, 160, 103, 154, 156, 93, 92, 157, 103, 88, 160, 108, 158, 89, 168, 92, 96, 151, 173, 103, 96, 156, 92, 158, 156, 153, 157, 90, 98, 155, 113, 158, 154, 156, 88, 87]\n"
          ]
        }
      ]
    }
  ]
}